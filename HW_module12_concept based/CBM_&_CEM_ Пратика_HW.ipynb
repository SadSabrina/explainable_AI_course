{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1C_4BOhXa7kv3V-7uzyQ3opV2sTfg5M1k","timestamp":1724923667260}],"authorship_tag":"ABX9TyNZOo0rK2skLoMwyaPOnfUa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **CEM & CBM: Практика**\n","\n","Привет, друзья!\n","Практика по CBM и CEM будет направлена на понимание теории моделей. В течение практики, мы будем опираться на статью [Concept Embedding Models:\n","Beyond the Accuracy-Explainability Trade-Off](https://arxiv.org/pdf/2209.09056) и примеры, приложенные в документации библиотеки [pyTorch explain](https://pytorch-explain.readthedocs.io/en/latest/index.html#).\n","\n","В течение практики, вы:\n","\n","*   Изучите возможности библиотеки pyTorch explain\n","*   Рассмотрите и реализуете CBM и CEM модели\n","*   С помощью построенных моделей решите тригонометрическую и XOR задачи\n","\n","Приятного кодинга!\n","\n","![Bootle](https://ucarecdn.com/ddf09dc0-e603-4943-b756-77ba9204f84d/)"],"metadata":{"id":"MI0QpcWeDvyL"}},{"cell_type":"markdown","source":["## PyTorch, Explain!\n","\n","PyTorch, Explain! — это библиотека для расширения возможностей PyTorch с целью разработки объяснимых моделей глубокого обучения. Библиотека содержит:\n","\n","- Специфические функции потерь, метрики и слои, для внедрения концептов в модель\n","- Обертки для интерпретации моделей, построенных на основе концепций\n","- Датасеты (бенчмарки) для оценки concept-based моделей\n","\n","Градиентных и других классических методов интерпретации библиотека не содержит, поэтому может быть полезна только в сценарии разработки concept-based сетей (Deep Concept Reasoners, CEM, CBM и Logic Explained Nets). В практике мы будем работать с CBM и CEM."],"metadata":{"id":"Q-bUw8w52uRG"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"0_ALYN1eOyr1","executionInfo":{"status":"ok","timestamp":1724924803288,"user_tz":-180,"elapsed":3226,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}}},"outputs":[],"source":["!pip install torch-explain -q # Установим pytorch-explain"]},{"cell_type":"markdown","source":["## Наборы данных.\n","\n","Разметка концептов, как мы с вами обсудили в модуле — времязатратно. Поэтому для оценки моделей мы будем использовать уже заранее подготовленые бенчмарки XOR и Dot.\n","\n","\n","**XOR data**\n","\n","Для усложнения классической задачи, датасет XOR в качестве входных признаков использует непрерывную пару значений $(x_1, x_2)$ из отрезка $[0, 1]$. Концептами в задаче являются булевы векторы, сформированные по правилу $(Bool(c_1 > 0.5), Bool(c_2 > 0.5))$\n","\n","\n","**Dot data**\n","\n","Набор данных, который создается следующим образом:\n","1. Берется 4 вектора  $v_1, v_2, w_1, w_2 ∈ R^2$, причем w_1 = (1, 1), w_2 = (-1, -1)\n","2. Для них строится объект $x = (x_1, x_2, x_3, x_4): x_1, x_2 =  v_1 + v_2, x_3, x_4 = v_1 - v_2$\n","2. На основе взятых векторов генерируются две концептуальные аннотации, указывающие смотрят ли $v_i, w_i$ в одном направлении.\n","3. Целевая переменная $y$ же представляет собой результат ответа на вопрос, смотрят ли $v_1$, $v_2$ (практически) в одном направлении\n","\n"],"metadata":{"id":"tbyByjIFFpRr"}},{"cell_type":"markdown","source":["**Материалы, если вам понравятся модели:**\n","\n","- [Репозиторий](https://github.com/yewsiang/ConceptBottleneck) с кодом из оригинальной статьи [Concept Bottleneck Models](https://arxiv.org/pdf/2007.04612)\n","- [Реализация](https://github.com/mateoespinosa/cem/tree/main) CEM на основе статей архитектуры на NeurIPS 2022\n","- Для более глубокой [практики](https://github.com/Trustworthy-ML-Lab/Label-free-CBM/tree/main) с CBM, на основе статьи [Label-free Concept Bottleneck Models](https://openreview.net/pdf?id=FlCg47MNvBA)"],"metadata":{"id":"cMlcvWoIdHi9"}},{"cell_type":"markdown","source":["Импортируем необходимые библиотеки для работы."],"metadata":{"id":"QnNom-EfIqNL"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","\n","import random\n","import numpy as np\n","\n","import torch_explain as te\n","from torch_explain import datasets\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","\n","# Сразу же загрузим первый датасет для практики\n","x_xor, c_xor, y_xor = datasets.xor(500)\n","x_xor_train, x_xor_test, c_xor_train, c_xor_test, y_xor_train, y_xor_test = train_test_split(x_xor, c_xor, y_xor,\n","                                                                            test_size=0.33,\n","                                                                            random_state=42)"],"metadata":{"id":"zoCAzro1ZXvL","executionInfo":{"status":"ok","timestamp":1724924803288,"user_tz":-180,"elapsed":3,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["**Concept Bottleneck Models**\n","\n","Вспомним, как выглядит CBM:\n","\n","![CBM_model](https://ucarecdn.com/96ae12f2-d0db-4d7e-851b-7240178c5593/-/crop/2303x803/24,0/-/preview/)\n","\n","\n","Математически CBM есть комбинация двух функций, $y = f(g(x)),$ где $g(x)$ — функция, ставящая в соответствие каждому входному объекту вектор концептов (`concept_encoder`), $f(g(x))$ —  функция, ставящая в соответствие каждому вектору концептов целевой ответ (`task_predictor`).\n","\n","Архитектура и `concept_encoder`, и `task_predictor` может быть любой, но в целом — это две обязательные составные части CBM модели.  "],"metadata":{"id":"TUPwLzoTJLMj"}},{"cell_type":"markdown","source":["**Доопределите модель, верно расставив размерности. Чему равны Task и Concept accuracy?**"],"metadata":{"id":"wCyU5eVdbmCo"}},{"cell_type":"code","source":["#Зафиксируем все сиды для возспроизводимости результатов\n","\n","np.random.seed(0)\n","random.seed(0)\n","torch.manual_seed(0)\n","\n","\n","class Concept_Bottleneck_Model(nn.Module): # Инициализация CBM модели\n","\n","  def __init__(self, input_size, hidden_size, concept_size, len_out):\n","    super(Concept_Bottleneck_Model, self).__init__()\n","\n","    # Часть 1: concept encoder\n","    self.concept_encoder = torch.nn.Sequential(torch.nn.Linear(input_size, hidden_size), # Линейный слой\n","                                               torch.nn.LeakyReLU(), # Функция активации с\n","                                               torch.nn.Linear(\"\", 8), # ПОСТАВЬТЕ РАЗМЕРНОСТЬ ЗДЕСЬ\n","                                               torch.nn.LeakyReLU(),\n","                                               torch.nn.Linear(\"\", concept_size), # ПОСТАВЬТЕ РАЗМЕРНОСТЬ ЗДЕСЬ\n","                                               torch.nn.Sigmoid())\n","    # Часть 2: task predictor\n","    self.task_predictor = torch.nn.Sequential(torch.nn.Linear(\"\", 4), # ПОСТАВЬТЕ РАЗМЕРНОСТЬ ЗДЕСЬ\n","                                               torch.nn.LeakyReLU(),\n","                                               torch.nn.Linear(4, len_out))\n","\n","  def forward(self, input):\n","\n","    c_pred = self.concept_encoder(input)\n","    y_pred = self.task_predictor(c_pred)\n","\n","    return c_pred, y_pred"],"metadata":{"id":"YdfLe_-xNmh_","executionInfo":{"status":"ok","timestamp":1724924803288,"user_tz":-180,"elapsed":3,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Теперь обучим модель на импортированном наборе данных."],"metadata":{"id":"WKYFncTJf2Dd"}},{"cell_type":"code","source":["# Определим инициализированную модель\n","XOR_CBM = Concept_Bottleneck_Model(x_xor.shape[1], 16, c_xor.shape[1], 1)\n","\n","# Определим функции потерь для концептов и классов, а также оптимизатор\n","\n","optimizer = torch.optim.AdamW(XOR_CBM.parameters(), lr=0.01)\n","loss_form_c = torch.nn.BCELoss()\n","loss_form_y = torch.nn.BCEWithLogitsLoss()\n","\n","# переходим в train mode\n","XOR_CBM.train()\n","\n","for epoch in range(2001):\n","    optimizer.zero_grad()\n","\n","    # прогнозируем концепты и задачу\n","    c_xor_pred = XOR_CBM.concept_encoder(x_xor_train)\n","    y_xor_pred = XOR_CBM.task_predictor(c_xor_pred)\n","\n","    # обновляем функции потерь (не меняйте коэффициент)\n","    concept_loss = loss_form_c(c_xor_pred, c_xor_train)\n","    task_loss = loss_form_y(y_xor_pred, y_xor_train)\n","    loss = concept_loss + 0.2*task_loss\n","\n","    loss.backward()\n","    optimizer.step()"],"metadata":{"id":"vY_37y0AO86b","executionInfo":{"status":"ok","timestamp":1724924807773,"user_tz":-180,"elapsed":4487,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["И решим задачу! Не забудьте занести ответы на степик."],"metadata":{"id":"tXXxtlVmges-"}},{"cell_type":"code","source":["c_xor_pred = XOR_CBM.concept_encoder(x_xor_test) # спрогнозируем концепты\n","y_xor_pred = XOR_CBM.task_predictor(c_xor_pred) # спрогнозируем решение задачи\n","\n","concept_xor_accuracy = accuracy_score(c_xor_test, c_xor_pred > 0.5)\n","task_xor_accuracy = accuracy_score(y_xor_test, y_xor_pred > 0)\n","\n","print(f'Concept accuracy: {concept_xor_accuracy}\\n Task accuracy: {task_xor_accuracy}')"],"metadata":{"id":"9YdUEtrmPJNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Оценим работу модели на парах концептов (1, 0), (0, 1), (1, 1), (0, 0)\n","\n","c_different = torch.FloatTensor([0, 1])\n","print(f\"f({c_different}) = {int(XOR_CBM.task_predictor(c_different).item() > 0)}\")\n","\n","c_different2 = torch.FloatTensor([1, 0])\n","print(f\"f({c_different2}) = {int(XOR_CBM.task_predictor(c_different2).item() > 0)}\")\n","\n","c_equal = torch.FloatTensor([1, 1])\n","print(f\"f({c_equal}) = {int(XOR_CBM.task_predictor(c_equal).item() > 0)}\")\n","\n","c_equal0 = torch.FloatTensor([0, 0])\n","print(f\"f({c_equal0}) = {int(XOR_CBM.task_predictor(c_equal0).item() > 0)}\")"],"metadata":{"id":"n_qbUMebayby"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["После обучения работа модели прозрачно, мы понимаем, что она выдает единицу при различных значениях для концептов и 0, если входные концепты различны. Отличная работа!\n","\n","Кроме того, обратите внимание на процесс обучения — обновление функции ошибки зависит лишь от 0.2 `task_loss`, поэтому большее внимание мы акцентируем на концептах. Что будет, если поменять это местами?"],"metadata":{"id":"agganJGrS8XB"}},{"cell_type":"code","source":["XOR_CBM = Concept_Bottleneck_Model(x_xor.shape[1], 16, c_xor.shape[1], 1)\n","\n","optimizer = torch.optim.AdamW(XOR_CBM.parameters(), lr=0.01)\n","loss_form_c = torch.nn.BCELoss()\n","loss_form_y = torch.nn.BCEWithLogitsLoss()\n","\n","XOR_CBM.train()\n","\n","for epoch in range(2001):\n","    optimizer.zero_grad()\n","\n","    # прогнозируем концепты и задачу\n","    c_xor_pred = XOR_CBM.concept_encoder(x_xor_train)\n","    y_xor_pred = XOR_CBM.task_predictor(c_xor_pred)\n","\n","    # обновляем функции потерь (не меняйте коэффициент)\n","    concept_loss = loss_form_c(c_xor_pred, c_xor_train)\n","    task_loss = loss_form_y(y_xor_pred, y_xor_train)\n","    loss = 0.2*concept_loss + task_loss\n","\n","    loss.backward()\n","    optimizer.step()"],"metadata":{"id":"z1ohlQBMIb-a","executionInfo":{"status":"ok","timestamp":1724924812482,"user_tz":-180,"elapsed":4711,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["c_xor_pred = XOR_CBM.concept_encoder(x_xor_test)\n","y_xor_pred = XOR_CBM.task_predictor(c_xor_pred)\n","\n","concept_xor_accuracy = accuracy_score(c_xor_test, c_xor_pred > 0.5)\n","task_xor_accuracy = accuracy_score(y_xor_test, y_xor_pred > 0)\n","\n","print(f'Concept accuracy: {concept_xor_accuracy}\\n Task accuracy: {task_xor_accuracy}')"],"metadata":{"id":"27ATb8SmIhve"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Точность для задачи и концептов значительно не изменилась. Выглядит, будто нет разницы в коэффициентах при loss (вы убедитесь в этом, если позапускаете процесс обучения с различными комбинациями), но такой факт справедлив только для этой задачи — она простая. Посмотрим на обучение CBM на задаче более сложной — используем dot dataset.\n","\n","Вы также можете убедиться в этом сами, но если запускать обучение с последовательно разным вкладом `concept` и `task_loss` для набора `dot data`, то точность обеих задач будет меняться от несильных до значимых диапазонов.\n","\n","![diff_taskconcept_losess3706c9e53c920e32.png](https://ltdfoto.ru/images/2024/08/28/diff_taskconcept_losess3706c9e53c920e32.png)\n","\n","**Проанализируйте изображения. Какой коэффициент вклада concept_loss в задачу обеспечивает наиболее равные точности для обеих задач?**\n","\n","Это явление называется ***accuracy-explainability trade-off***. Когда исследователь стремится к более высокой точности, объяснения, предоставляемые моделями, имеют тенденцию ухудшаться по качеству и корректности, и наоборот. Переход от Concept Bottleneck Models к Concept Embedding Models частично решает эту проблему.\n","\n","В следующей части практики вы в этом убедитесь, сравнив производительность CBM и CEM на наборе данных dot самостоятельно."],"metadata":{"id":"rafrHXD8Il1n"}},{"cell_type":"markdown","source":["**Посмотрите на код генерации dot_data на степик. Какие части плоскости разделяют концепты в dot data?**"],"metadata":{"id":"yFpPdDiQci6u"}},{"cell_type":"code","source":["#Загрузим набор данных и выделим тренировочную и тестовую выборки\n","\n","x_dot, c_dot, y_dot = datasets.dot(500)\n","x_dot_train, x_dot_test, c_dot_train, c_dot_test, y_dot_train, y_dot_test = train_test_split(x_dot, c_dot, y_dot,\n","                                                                     test_size=0.33, random_state=42)"],"metadata":{"id":"LnL0pcSuTEmw","executionInfo":{"status":"ok","timestamp":1724924812482,"user_tz":-180,"elapsed":3,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Обучим модель concept-based модель, на лучшей комбинации concept и task losses. **Выберите её на степик, проверьте свой ответ и обучите модель.**"],"metadata":{"id":"dyGDnx6xcvjZ"}},{"cell_type":"code","source":["DOT_CBM = Concept_Bottleneck_Model(x_dot.shape[1], 16, c_dot.shape[1], 1)\n","\n","optimizer = torch.optim.AdamW(DOT_CBM.parameters(), lr=0.01)\n","loss_form_c = torch.nn.BCELoss()\n","loss_form_y = torch.nn.BCEWithLogitsLoss()\n","\n","DOT_CBM.train()\n","\n","for epoch in range(2001):\n","\n","  optimizer.zero_grad()\n","\n","  # прогнозируем концепты и задачу\n","  c_dot_pred = DOT_CBM.concept_encoder(x_dot_train)\n","  y_dot_pred = DOT_CBM.task_predictor(c_dot_pred)\n","\n","  # обновляем функции потерь (не меняйте коэффициент)\n","  concept_loss = loss_form_c(c_dot_pred, c_dot_train)\n","  task_loss = loss_form_y(y_dot_pred, y_dot_train)\n","  loss = #ВАШ_КОЭФФ*concept_loss + task_loss\n","\n","  loss.backward()\n","  optimizer.step()\n","\n"],"metadata":{"id":"TsEaKE-fcs5l","executionInfo":{"status":"ok","timestamp":1724924816172,"user_tz":-180,"elapsed":3693,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["c_dot_pred = DOT_CBM.concept_encoder(x_dot_test)\n","y_dot_pred = DOT_CBM.task_predictor(c_dot_pred)\n","\n","concept_dot_accuracy = accuracy_score(c_dot_test, c_dot_pred > 0.5)\n","task_dot_accuracy = accuracy_score(y_dot_test, y_dot_pred > 0)\n","\n","print(f'Concept accuracy: {concept_dot_accuracy}\\n Task accuracy: {task_dot_accuracy}')"],"metadata":{"id":"D22HBYsdd6Cl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Точность концептов можно назвать неудовлетворительной, хотя задача моделью решается вполне сносно."],"metadata":{"id":"WwzpmPVLfYjI"}},{"cell_type":"markdown","source":["## От CBM к CEM\n","Создадим класс  Concept Embedding Model. Структура этой модели несколько отлична от структуры CBM.\n","\n","![CBM](https://ucarecdn.com/9626f7a1-c054-4f97-86da-50fb7f61b778/)\n","\n","**В машинном обучении есть похожие подходы — когда одной моделью мы прогнозируем какую-то переменную в задаче, а потом вызываем получение прогноза при помощи другой — метамодели. Как называются эти подходы?**"],"metadata":{"id":"G4Hv9E2XiQNW"}},{"cell_type":"markdown","source":["С одной стороны, можно зашить эту структуру в модель самостоятельно. С другой, благодаря возможностям библиотеки pytorchExplain! это можно сделать добавив в модель часть `te.nn.ConceptEmbedding(10, concept_size, embedding_size)`"],"metadata":{"id":"CpDVkwbcjT0y"}},{"cell_type":"code","source":["class Concept_Embedding_Model(nn.Module): #  Создадим класс CEM\n","\n","  def __init__(self, input_size, hidden_size, concept_size, embedding_size, len_out):\n","    super(Concept_Embedding_Model, self).__init__()\n","\n","    # Часть 1 + 2: latent code + Concept Embedding generator\n","    self.latetnt_code = torch.nn.Sequential(torch.nn.Linear(input_size, hidden_size),\n","                                               torch.nn.LeakyReLU(),\n","                                               torch.nn.Linear(hidden_size, 10),\n","                                               torch.nn.LeakyReLU(),\n","                                               te.nn.ConceptEmbedding(10, concept_size, embedding_size), # добавляем слой, ответственный за эмбеддинги концептов\n","                                               )\n","    # Часть 2: task predictor\n","    self.task_predictor = torch.nn.Sequential(torch.nn.Linear(concept_size*embedding_size, 5),\n","                                               torch.nn.LeakyReLU(),\n","                                               torch.nn.Linear(5, len_out))\n","\n","  def forward(self, input):\n","\n","    c_emd, c_pred  = self.latetnt_code(input)\n","    y_pred = self.task_predictor(c_pred)\n","\n","    return c_emd, c_pred, y_pred"],"metadata":{"id":"VORFN42iWEYu","executionInfo":{"status":"ok","timestamp":1724924816172,"user_tz":-180,"elapsed":2,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Обучим нашу CEM и проверим качество."],"metadata":{"id":"aj2HKTL6iMMN"}},{"cell_type":"code","source":["CEM = Concept_Embedding_Model(x_dot.shape[1], 16, c_dot.shape[1], 8, 1)\n","\n","optimizer = torch.optim.AdamW(CEM.parameters(), lr=0.01)\n","loss_form_c = torch.nn.BCELoss()\n","loss_form_y = torch.nn.BCEWithLogitsLoss()\n","CEM.train()\n","for epoch in range(2001):\n","    optimizer.zero_grad()\n","\n","    # прогнозируем эбмдеддинги и метки концептов\n","    c_emb, c_pred = CEM.latetnt_code(x_dot_train)\n","    y_pred = CEM.task_predictor(c_emb.reshape(len(c_emb), -1))\n","\n","    # вычисляем функцию потерь\n","    concept_loss = loss_form_c(c_pred, c_dot_train)\n","    task_loss = loss_form_y(y_pred, y_dot_train)\n","    loss = concept_loss + 0.3*task_loss\n","\n","    loss.backward()\n","    optimizer.step()"],"metadata":{"id":"-H1sPozYlFsx","executionInfo":{"status":"ok","timestamp":1724924823345,"user_tz":-180,"elapsed":7175,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Проверим качество решения задачи\n","\n","c_dot_emb, c_dot_pred = CEM.latetnt_code.forward(x_dot_test)\n","y_dot_pred = CEM.task_predictor(c_dot_emb.reshape(len(c_dot_emb), -1))\n","\n","concept_dot_accuracy = accuracy_score(c_dot_test, c_dot_pred > 0.5)\n","task_dot_accuracy = accuracy_score(y_dot_test, y_dot_pred > 0)\n","\n","print(f'Concept accuracy: {concept_dot_accuracy}\\n Task accuracy: {task_dot_accuracy}')"],"metadata":{"id":"4KinLZHPlc79"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Вот так — *одна строка* архитектуры позволила нам повысить и практически сопоставить точности как в решении задачи нахождения концептов, так и в решении целевой задачи!"],"metadata":{"id":"ey_UbU7Sf0VD"}},{"cell_type":"markdown","source":["pytorch_explain! предоставляет ещё много других стратегий реализации более интерпретируемых concept-based моделей. Надеюсь, эта домашка-туториал смогла вас заинтересовать!\n","\n","**Спасибо за практику и до новых встреч!**"],"metadata":{"id":"1miVoJWPgDcp"}},{"cell_type":"markdown","source":["**Примечание:**\n","\n","Другой способ реализации CEM представлен [здесь](https://github.com/mateoespinosa/cem/tree/main). Однако он на 29.08.2014 не являлся рабочим."],"metadata":{"id":"652FvWfYctYE"}}]}