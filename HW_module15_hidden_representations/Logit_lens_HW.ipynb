{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng49HHFSi60S"
      },
      "source": [
        "# **Logit Lens: практика**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKMviqeei-0Y"
      },
      "source": [
        "Привет, друзья! Добро пожаловать на практику по Logit Lens. В этой работе вы шаг за шагом реализуете логит-линзу — начиная, как всегда, от анализа архитектуры и заканчивая построением результатов.\n",
        "\n",
        "Во время выполнения практики, вы:\n",
        "\n",
        "* Проанилизруете ахитектуру GPT-2;\n",
        "* Соберете логиты с каждой необходимой компоненты модели;\n",
        "* Построите визуализацию полученного результата;\n",
        "* Познакомитесь с билиотекой NNsight для упрощения построения логит-линз;\n",
        "\n",
        "\n",
        "[Оригинальная статья о LogitLiens](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)\n",
        "\n",
        "\n",
        "Приступим!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Часть 1. Logit Lens своими руками**"
      ],
      "metadata": {
        "id": "P3WbAJorWYsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo==1.8.0 -q"
      ],
      "metadata": {
        "id": "FAcgQigOTu5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VsZHFh7Fi4X"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from IPython.display import clear_output\n",
        "from typing import List, Callable\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from torchinfo import summary\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начнем с загрузки модели."
      ],
      "metadata": {
        "id": "MrbegXzwUMyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "8MCPrtn6aIEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 1. Вызовите атрибут ._modules у модели. Сколько модулей верхнего уровня вы получили?**"
      ],
      "metadata": {
        "id": "R3PuK5JMUZC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь"
      ],
      "metadata": {
        "id": "5rweO2CMUg8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим процесс преобразования входного примера в GPT-2 step by step. Для этого напишем простой `input` и проанилизуем информацию о модели"
      ],
      "metadata": {
        "id": "7TosaM2jUsb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Are cats good?\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "\n",
        "input0 = torch.tensor(\n",
        "    [[tokenizer.encode(text, add_special_tokens=True)]]\n",
        ")\n",
        "outputs = model(input0)\n",
        "\n",
        "summary(model, input_data=input0)"
      ],
      "metadata": {
        "id": "6hsR3z1_A44T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 2-4. Изучите карточку, полученную выше. Ответьте на вопросы:**\n",
        "\n",
        "**1. Сколько всего параметров в модели?** 163,037,184 \\\n",
        "**2. Сколько в модели блоков трансфомера?** 12 \\\n",
        "**3. Сколько в модели выходных значений (токенов)?** 50257 \\"
      ],
      "metadata": {
        "id": "Fz5XZ3stVLpy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отлично, вы примерно посмотрели на модель. Теперь посмотрим, как она работает — пропустим input через модель, с целью получить не только информацию о скрытых состояниях и выходны логитах, но и генерацию какого-то текста."
      ],
      "metadata": {
        "id": "3peZ49byV1u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_ids = model.generate(**encoded_input, max_length=14, min_length=14, return_dict_in_generate=True, output_hidden_states=True)\n",
        "\n",
        "# Декодирование\n",
        "output_text = tokenizer.decode(output_ids[0][0], skip_special_tokens=True)\n",
        "output_text"
      ],
      "metadata": {
        "id": "BOuA5TM0idNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обратите внимание:** первые выходные токены генерации — в точности равны input'у.\n",
        "\n",
        "**Задание 5. Сравните `output_ids['sequences']` и `encoded_input['input_ids']`. Сколько следующих за входными токенов сгенерировала модель?**"
      ],
      "metadata": {
        "id": "il5mEx57WUJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь"
      ],
      "metadata": {
        "id": "J0lJJpws1OJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь"
      ],
      "metadata": {
        "id": "tgW8Bl6qWpAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 6. Сколько токенов сгенерировала модель всего?**\n",
        "\n"
      ],
      "metadata": {
        "id": "OOSFAXlkXyd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь"
      ],
      "metadata": {
        "id": "OICXnaOFXs5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь рассмотрим скрытые состояния. Всего их в значении полученного словаря 10. Однако, блоков трансформера в модели 12 и, кроме того, скрытое состояние фиксируется после слоя `embedding`.\n",
        "\n",
        "**Почему для нашего входа мы получили 10 скрытых состояний:** \\\n",
        "\n",
        "Для GPT моделей возвращаются `hidden states` каждого сгенерированного токена и для них идёт детализация `hidden states` модели. То есть, так как у нас было сгенерировано 10 новых токенов, то у нас получается по 13 скрытых состояний на каждый токен.  \n",
        "\n"
      ],
      "metadata": {
        "id": "r75TKijqmtcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hs_tokens_cnt = len(output_ids['hidden_states'])\n",
        "hs_f_each_tokens_cnt = len(output_ids['hidden_states'][0])\n",
        "\n",
        "print(f'Количество токенов, для которых сгенерированы скрытые состояния {hs_tokens_cnt}\\nКоличество скрытых состояний на токен: {hs_f_each_tokens_cnt}')"
      ],
      "metadata": {
        "id": "oa9eQ8FIm8Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ещё раз закрепим:**\n",
        "\n",
        "Для каждого сгенерированного токена, 13 скрытых состояний. Вы можете убедиться в этом, позапускав код ниже с разными токенами (менять только первую строку).\n",
        "\n",
        "Кстати, обратите внимание, что для токена 198 (значение `\\n`) у нас только один набор скрытых состояний. Отсюда, имеем:\n",
        "\n",
        "* Набор скрытых состояний 0 для входных значений: `tensor([ 8491, 11875,   922,    30])`\n",
        "* Набор скрытых состояний  1 для токена: `tensor([198])`\n",
        "* Набор скрытых состояний 2 для токена: `tensor([464])`\n",
        "* Набор скрытых состояний 3 для токена: `tensor([3280])`\n",
        "* Набор скрытых состояний 4 для токена: `tensor([318])`\n",
        "* Набор скрытых состояний 5 для токена: `tensor([3763])`\n",
        "* Набор скрытых состояний 6 для токена: `tensor([13])`\n",
        "* Набор скрытых состояний 7 для токена: `tensor([28997])`\n",
        "* Набор скрытых состояний 8 для токена: `tensor([389])`\n",
        "* Набор скрытых состояний 9 для токена: `tensor([922])`\n",
        "\n"
      ],
      "metadata": {
        "id": "jAN9f8iioQrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract hidden states (last layer)\n",
        "hidden_states = output_ids.hidden_states[0]  # Скрытые состояния i-го токена, строка, в которой можно перебирать номера\n",
        "\n",
        "last_hidden_state = hidden_states[0]  # Последнее состояние i-го токена\n",
        "\n",
        "# Извлекаем последние слои для проекции на словарь\n",
        "lm_head = model.lm_head  # linear layer to dict\n",
        "\n",
        "# Преобразуем hidden states в logits вручную\n",
        "logits_from_hidden_states = lm_head(last_hidden_state)  # (batch_size, seq_length, vocab_size)\n",
        "\n",
        "# Проверяем корректность размерность\n",
        "print(f\"Logits shape: {logits_from_hidden_states.shape}\")  # Should be (batch_size, seq_length, vocab_size)\n",
        "\n",
        "# Конвертируем logits в предикты (argmax по vocab size)\n",
        "predicted_token_ids = torch.argmax(logits_from_hidden_states, dim=-1)\n",
        "\n",
        "# Декодируем predicted tokens\n",
        "decoded_predictions = tokenizer.batch_decode(predicted_token_ids, skip_special_tokens=True)\n",
        "\n",
        "# Результаты\n",
        "print(f\"Predicted tokens:\\n{decoded_predictions}\")"
      ],
      "metadata": {
        "id": "O-l9k8qxfZO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, поняв, что мы собираем для каждого токена мы можем собрать проекции по всем токенам."
      ],
      "metadata": {
        "id": "Yecj87fNrtVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lens_dict = {}\n",
        "logits_dict = {}\n",
        "\n",
        "for token_idx, token_hidden_states in enumerate(output_ids.hidden_states): # для кортежа скрытых состояний каждого токена\n",
        "  lens_dict[token_idx] = []\n",
        "  logits_dict[token_idx] = []\n",
        "\n",
        "  for hidden_idx, hidden in enumerate(token_hidden_states): # для кадого скрытого состояния внутри\n",
        "\n",
        "    logits = lm_head(hidden) # извлекаем логиты\n",
        "\n",
        "    probs = torch.nn.functional.softmax(logits, dim=-1) # извлекаем вероятности\n",
        "    predicted =  torch.argmax(probs, dim=-1) # извлекаем номер спрогнозированного токена\n",
        "\n",
        "    proba =  torch.max(probs, dim=-1).values # извлекаем вероятность спрогнозированного токена\n",
        "    logits_dict[token_idx].append(proba)\n",
        "\n",
        "    decoded = tokenizer.batch_decode(predicted, skip_special_tokens=True)\n",
        "    lens_dict[token_idx].append(decoded[0])"
      ],
      "metadata": {
        "id": "Uj3V4GWrpoPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание 7. Сколько всего проекций у вас получилось?**"
      ],
      "metadata": {
        "id": "ll42g0pOrzVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код здесь для каждого токена (их 10) 13 скрытых состояний = 10*13"
      ],
      "metadata": {
        "id": "VCh6s0Vpomri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, прежде чем визуализировать результат, удалим первые токены и логиты, так как они отражают input. Кроме того, первый выход содержит несколько токенов, что не удобно для отображения на графике."
      ],
      "metadata": {
        "id": "b2oGrDmCvxEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits_dict.pop(0)\n",
        "lens_dict.pop(0)"
      ],
      "metadata": {
        "id": "Gp05Ag7xy-4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Визуализация результата**"
      ],
      "metadata": {
        "id": "hYCS_g3BsV_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перейдем к визуализации. Все собранные логиты и токены можно рассмотреть как матрицы, где строки — это скрытых слоев, а столбцы — токены.\n",
        "\n",
        "* Первая строка — представление сгенерированных токенов на 1 скрытом слое; \\\n",
        "* Вторая строка — представление сгенерированных токенов на 2 скрытом слое;\n",
        "* ...и так далее...\n",
        "* Последняя строка — представление сгенерированных токенов на 13м скрытом слое (посленднем энкодере модели).\n",
        "\n",
        "Матрицу, в свою очередь, можно визуилизровать как тепловую карту. Это реализовано ниже шаг за шагом."
      ],
      "metadata": {
        "id": "55M0E4fxNo8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим матрицу для вероятностей\n",
        "probs_matrix = []\n",
        "tokens_matrix = []\n",
        "\n",
        "# Перебираем все токены\n",
        "for token_idx in range(1, len(lens_dict)+1):\n",
        "    probs_matrix.append(logits_dict[token_idx])  # Собираем вероятности\n",
        "    tokens_matrix.append(lens_dict[token_idx])  # Собираем токены\n",
        "\n",
        "# Преобразуем оба словаря в numpy для удобства работы с тепловыми картами\n",
        "probs_matrix = torch.stack([torch.tensor(i) for i in probs_matrix], dim=1).numpy()\n",
        "tokens_matrix = np.stack([i for i in tokens_matrix])\n",
        "\n",
        "# Визуализируем вероятности с помощью тепловой карты\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(probs_matrix, cmap='YlGnBu', annot=True, fmt=\".2f\", cbar=True)\n",
        "\n",
        "# Настроим метки на осях\n",
        "plt.title(\"Logit Lens: Token Probabilities Across Layers\")\n",
        "plt.xlabel(\"Hidden States (Token Indexes)\")\n",
        "plt.ylabel(\"Layers\")\n",
        "plt.yticks(ticks=[i - 0.5 for i in range(1, len(lens_dict[1]) +1)], labels=[f'Layer {i}' for i in range(1, len(lens_dict[1]) + 1)], rotation=0)\n",
        "plt.xticks(ticks=[i + 0.5 for i in range(0, len(lens_dict))], labels=[f\"Token {i+1}\" for i in range(0, len(lens_dict))])\n",
        "\n",
        "# И покажем карту\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yvviiyAyweHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью `matplotlib` мы можем визуализировать в виде тепловой карты только логиты. Идеально было бы на каждую ячейку наложить вместе с логитами также спрогнозированные слова.\n",
        "\n",
        "Это можно делать с помощью `plotly` — интерактивной (но сильно более тяжелой по памяти) библиотеки для визуализации. Ниже я также привожу код и для неё.\n"
      ],
      "metadata": {
        "id": "chtXPtWAScem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_token_ids = output_ids['sequences'][0][5:] # выходные токены, для записи их номеров по оси х"
      ],
      "metadata": {
        "id": "rEg7kXWfwfHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.imshow(\n",
        "    probs_matrix, # матрица вероятностьй\n",
        "    x=[str(i.item()) for i in output_token_ids], # выходные токены, для записи их номеров по оси х\n",
        "   # y=[f'L-r {i}' for i in list(range(len(tokens_matrix.T)))], # для отображения на оси y названий (опционально)\n",
        "    color_continuous_scale=px.colors.diverging.RdYlBu_r, # смена циврофой палитры\n",
        "    color_continuous_midpoint=0.50,  # центральная точка для цветовой палитры — у нас это 0.5, так как логиты мы преобразовали в вероятности\n",
        "    labels=dict(x=\"Out Tokens\", y=\"Layers\", color=\"Probability\") # названия для осби x, y и colorbar\n",
        ")\n",
        "\n",
        "# нанесение названия на график\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Logit Lens Visualization'\n",
        ")\n",
        "\n",
        "# нанесение текста на ячейки\n",
        "\n",
        "fig.update_traces(text=tokens_matrix.T, texttemplate=\"%{text}\")\n",
        "\n",
        "# визуализация фигуры\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CUcw66P3vsoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Зафиксируем выводы из графика:\n",
        "\n",
        "1. Выходы логит-линзы на первом слое приближенно равны выходам логит-линзы на последнем слое со сдвигом;\n",
        "2. Вероятности не имеют стабильного повышения или понижения по слоям. На средних слоях модель наиболее уверенна в токенах;"
      ],
      "metadata": {
        "id": "gU5jUdSOUaTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Часть 2. NNsight**\n",
        "\n",
        "\n",
        "[NNsight](https://nnsight.net/) — библиотека, которая за счет внутренних оптимизаций, позволяет обвешивать Hf модельки так, чтобы извлекать скрытые состояния для дальнейшего анализа быстро и просто.\n",
        "\n",
        "**Преимущества библиотеки:**\n",
        "\n",
        "1. Скорость запуска;\n",
        "2. Уобный интерфейс;\n",
        "3. Плюс понятные туториалы с визуализациями.\n",
        "\n",
        "**Некоторые недостатки:**\n",
        "\n",
        "Как пишут авторы, библиотека находится на стадии становления. Поэтому в бибилотеке еще есть что улучшать.\n",
        "\n",
        "1. Не все модели с Hf грузятся.\n",
        "2. Читатели моего блога поделились, что при использовании могут быть ошибки с градиентами в графе.\n",
        "\n",
        "Однако для учебы целей — библиотека великолепна! Давайте посмотрим, как построить линзу с её помощью.\n",
        "\n"
      ],
      "metadata": {
        "id": "0UcH0FMqSMwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U nnsight -q"
      ],
      "metadata": {
        "id": "CfXaWJy8SMRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данной библиотеке модели загружаются в классы обертки при помощи синтаксика, аналогичного transformers."
      ],
      "metadata": {
        "id": "rOWrrn6NWoAq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv4b1dGYjYNh"
      },
      "outputs": [],
      "source": [
        "# Загрузка GPT2\n",
        "from nnsight import LanguageModel\n",
        "\n",
        "model_NN = LanguageModel(\"openai-community/gpt2\", device_map=\"auto\", dispatch=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULg0CFgO9gbp"
      },
      "source": [
        "Посмотрим на архитектуру модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzSdXMcTjhgx"
      },
      "outputs": [],
      "source": [
        "print(model_NN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Архитектура почти не различается. Разве что есть компоненты `transformer`, `generator`, `streamer`. В документации они точно не описаны.\n",
        "\n",
        "Теперь посмотрим на реализацию логит-линзы из [туториала](http://nnsight.net/notebooks/tutorials/logit_lens/) авторов библиотеки. Воспроизведем его с тем же текстом, что мы использовали для линзы, построенной вручную."
      ],
      "metadata": {
        "id": "-MDrXy-1a8DP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2OkUOXQjmHL"
      },
      "outputs": [],
      "source": [
        "prompt= \"Аre cats good?\"\n",
        "layers = model_NN.transformer.h\n",
        "probs_layers = []\n",
        "\n",
        "with model_NN.trace() as tracer:\n",
        "    with tracer.invoke(prompt) as invoker:\n",
        "        for layer_idx, layer in enumerate(layers):\n",
        "\n",
        "            # Преобразование head + layer normalization\n",
        "            layer_output = model_NN.lm_head(model_NN.transformer.ln_f(layer.output[0]))\n",
        "\n",
        "            # Применение softmax\n",
        "            probs = torch.nn.functional.softmax(layer_output, dim=-1).save()\n",
        "            probs_layers.append(probs)\n",
        "\n",
        "probs = torch.cat([probs.value for probs in probs_layers])\n",
        "\n",
        "# Забираем максимальные вероятности\n",
        "max_probs, tokens = probs.max(dim=-1)\n",
        "\n",
        "# Декодируем id в токены\n",
        "words = [[model_NN.tokenizer.decode(t.cpu()).encode(\"unicode_escape\").decode() for t in layer_tokens]\n",
        "    for layer_tokens in tokens]\n",
        "\n",
        "# 'input_ids'\n",
        "input_words = [model_NN.tokenizer.decode(t) for t in invoker.inputs[0][0][\"input_ids\"][0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcFbmC1XjoQ2"
      },
      "source": [
        "## **Визуализация**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdzaJn2xVDue"
      },
      "outputs": [],
      "source": [
        "pio.renderers.default = \"colab\"\n",
        "\n",
        "\n",
        "fig = px.imshow(\n",
        "    max_probs.detach().cpu().numpy(),\n",
        "    x=input_words,\n",
        "    y=list(range(len(words))),\n",
        "    color_continuous_scale=px.colors.diverging.RdYlBu_r,\n",
        "    color_continuous_midpoint=0.50,\n",
        "    text_auto=True,\n",
        "    labels=dict(x=\"Input Tokens\", y=\"Layers\", color=\"Probability\")\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Logit Lens Visualization',\n",
        "    xaxis_tickangle=0\n",
        ")\n",
        "\n",
        "fig.update_traces(text=words, texttemplate=\"%{text}\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7-5TdX2j6V2"
      },
      "source": [
        "Обратите внимание, что результаты не соотносятся. И это подсвечивает проблему в использовании оберточных библиотек — вы не полностью контроллируете результат и не можете увидеть каждую компоненту, которая к нему приводит.\n",
        "\n",
        "\n",
        "Спасибо за вашу работу!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}