{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Vj7kMcHYV7AjP5pUxU9flKzIiO1lQukZ","timestamp":1722674865574}],"mount_file_id":"1Vj7kMcHYV7AjP5pUxU9flKzIiO1lQukZ","authorship_tag":"ABX9TyNaMVP6s4P6pfrxbbve/usw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Guided BackPropagation: Практика\n","\n","Как мы с вами увидели в теории, Guided Backpropagation — это не только самостоятельный метод для решения задачи интерпретации, но и составная часть других методов.\n","\n","Guided Backpropagation является модификацией обычного алгоритма Vanilla Gradients. Главное отличие — в нём акцент идет только на те градиенты, что были больше нуля.  пропускаются только через положительные активации, что позволяет получить более четкие и интерпретируемые визуализации.\n","\n","В этой практике рассмотрим, как применить метод Guided Backpropagation к глубокой нейронной сети для визуализации влияния различных входных признаков на выходное предсказание.\n","\n","**Цели практики:**\n","\n","- Понять основные концепции метода Guided Backpropagation\n","- Научиться применять этот метод на практике\n","- Самостоятельно реализовать класс Guided_backprop для моделей ResNet и AlexNet\n","\n","<a href=\"https://ibb.co/gj69gg0\"><img src=\"https://i.ibb.co/dW7MKKN/tim-foster-w-X64-Gjbclg-unsplash.jpg\" alt=\"tim-foster-w-X64-Gjbclg-unsplash\" border=\"0\"></a>"],"metadata":{"id":"MYnIDXGmWb8H"}},{"cell_type":"markdown","source":["**Quiz 1.**Начнем с вспоминания пройденного. Ответьте — что такое Hook в pyTorch?\n","\n","**Ваш ответ:**\n","\n","\n","*   Механизм для регуляризация градиентов\n","*   Механизм, который позволяет пользователям встраивать свои функции в процесс работы модели\n","* Способ для ускорения обучения\n","* Способ для нормализации функции потерь\n","\n","\n"],"metadata":{"id":"Xp8BZXqBdgTN"}},{"cell_type":"markdown","source":["Хуки понадобятся нам для реализации Guided backpropagation. Создадим шаблон класса, который будет его осуществлять."],"metadata":{"id":"pGPfkeZiiy9N"}},{"cell_type":"markdown","source":["\n","\n","```\n","class Guided_backprop():\n","\n","    def __init__(self, model):\n","        self.model = model\n","        self.image_reconstruction = None # Здесь будет итоговая карта активаций\n","        self.activation_maps = []  # сюда будем записывать f1, f2, ...\n","        self.model.eval()\n","        self.register_hooks()\n","\n","    def register_hooks(self):\n","        def first_layer_hook_fn(module, grad_in, grad_out): # здесь будет функция для перехвата первого слоя\n","            pass\n","\n","        def forward_hook_fn(module, input, output): # здесь будет функция для forward hook\n","            pass\n","\n","        def backward_hook_fn(module, grad_in, grad_out): # здесь будет функция для backward hook\n","            pass\n","\n","\n","    def visualize(self, input_image, target_class):\n","\n","        model_output = self.model(input_image)\n","        pass\n","```\n","\n"],"metadata":{"id":"k58QArKei_SC"}},{"cell_type":"markdown","source":["Загрузим изображение с которым будем работать. Для интереса, рассмотрим пример, на котором находятся объекты сразу двух классов."],"metadata":{"id":"trTDyq6Ig-jN"}},{"cell_type":"code","source":["# импортируем необходимые библиотеки\n","import torch\n","import requests\n","import numpy as np\n","from io import BytesIO\n","from torch import nn\n","from torchvision import models, transforms\n","from PIL import Image\n","import matplotlib.pyplot as plt"],"metadata":{"id":"JBymtwgRUtbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Загрузка изображения\n","url = 'https://github.com/aiedu-courses/all_datasets/blob/main/images/cat_and_dog.jpg?raw=true'\n","\n","image_bytes = requests.get(url).content\n","image = Image.open(BytesIO(image_bytes)) # Снова рассмотрим конкретный пример x_0\n","\n","# Преобразуем изображение для подачи обученной сети\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    # Ваш код здесь\n","])\n","\n","\n","tensor = transform(image).unsqueeze(0).requires_grad_()"],"metadata":{"id":"bklHL5_ahCh9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Quiz 2** Закончите функцию `transform`. Добавьте нормализацию (`transforms.Normalize`) с классическими средним и стандартным отклонением для ImageNet. В ответ укажите значение с координатами `tensor[0, 1, 1, 1]`  "],"metadata":{"id":"tflp3lufhSdO"}},{"cell_type":"code","source":["# Ваш код здесь"],"metadata":{"id":"5ZN5Tjtohs4O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Теперь загрузим модель. Будем работать с resnet50.\n"],"metadata":{"id":"5tsBPcUsiooF"}},{"cell_type":"code","source":["model = models.resnet50(pretrained=True)\n","model.eval();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KrZF1L6tZb1Y","executionInfo":{"status":"ok","timestamp":1722258243244,"user_tz":-240,"elapsed":829,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}},"outputId":"be14f04c-e4ff-461a-ae4b-959c3c6231d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"markdown","source":["**Quiz 3** Примените модель к изображению. Какой класс она спрогнозировала? В ответ укажите номер класса."],"metadata":{"id":"B8V4SJp2jrbU"}},{"cell_type":"code","source":["# Ваш код здесь"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_mlM6B2j0Pk","executionInfo":{"status":"ok","timestamp":1722258252836,"user_tz":-240,"elapsed":4,"user":{"displayName":"Сабрина Садиех","userId":"02783317471993275941"}},"outputId":"f2edcd65-dc05-43e8-854c-4127b3b28ff9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(179)"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["- Начнем дополнять класс для реализации Guided backpropagation. Начнем с `forward_hook_fn(module, input, output)`. Данный хук нужен нам, чтобы хранить карты, *получающиеся на определенных слоях* при прямом проходе.\n","\n","**Quiz 4** Согласно этой логике, выберите правильную реализацию\n","\n","```\n","`forward_hook_fn` на степик и запишите её в шаблон класса.\n","\n"," def forward_hook_fn(module, input, output):\n","            # Выберите функцию на степик\n","```\n","\n","\n"],"metadata":{"id":"bh9s_VoUl7Xf"}},{"cell_type":"markdown","source":["- Теперь подумаем над `backward hook`.\n","\n","**Quiz 5** Смотря на реализованный код, расставьте на платформе правильный порядок шагов для него.\n","\n","\n","```\n","def backward_hook_fn(module, grad_in, grad_out):\n","            grad = self.activation_maps.pop()\n","            grad[grad > 0] = 1\n","            \n","            positive_grad_out = torch.clamp(grad_out[0], min=0.0)\n","            new_grad_in = positive_grad_out * grad\n","\n","            return (new_grad_in,)\n","```\n","\n","\n"],"metadata":{"id":"fq08Se4QokX-"}},{"cell_type":"markdown","source":["- Также нам понадобится сохранить карту признаков изображения ($f^0$). Обычно рассматривается входное изображение, которое можно определить как input при forward для первого слоя модели, то есть:\n","\n","\n","```\n","def first_layer_hook_fn(module, grad_in, grad_out):\n","            self.image_reconstruction = grad_in[0]\n","```\n","\n"],"metadata":{"id":"U34EmMWvq-GH"}},{"cell_type":"markdown","source":["**Отлично! Теперь реализуем все преобразования, которые наш Guided Backpropagation должен выполнять.**\n","\n","Во-первых, нам необходимо извлечь все составляющие модели.\n","\n","`modules = list(self.model.named_modules())`\n","\n","Далее, мы будем применять forward и backward hook от конца к началу. Для всех преобразований изображения, кроме первого, мы будем регистрировать forward и backward хуки только после *определенных* слоев. Помните, после каких (ответ етсь в теории на степик)?\n","\n","Хуки на первом слое снимем только после прохода по слоям предшествующим.\n","\n","**Quiz 6**\n","Проверку соответствия слоя определенному типу можно осуществить функция `isinstance(object, type)`. Что должно находиться на месте типа для нашего случая?\n","\n","Выберите ответ на степик и дополните код.\n","\n","```\n","for name, module in modules:\n","  if isinstance(module, # Ваш ответ здесь):\n","    module.register_forward_hook(forward_hook_fn)\n","    module.register_backward_hook(backward_hook_fn)\n","```\n","\n","\n","\n","        ##RESNET\n","\n","        if 'resnet' in identify_model(self.model).lower():\n","          first_layer = modules[1][1]\n","          first_layer.register_backward_hook(first_layer_hook_fn)\n","\n","        ###ALEXNET\n","\n","        if 'alexnet' in identify_model(self.model).lower():\n","          first_layer = modules[1][1][0]\n","          first_layer.register_backward_hook(first_layer_hook_fn)"],"metadata":{"id":"Ad0DwVPkrouL"}},{"cell_type":"markdown","source":["**На этом шаге реализована основвная часть Guided Backpropagation. Осталось добавить возможность визуализировать прогноз и готово!**\n","\n","Визуализацию опишем по такой логике:\n","\n","```\n","\n"," def visualize(self, input_image, target_class):\n","\n","\n","        model_output = self.model(input_image) # прогнозируем класс\n","        self.model.zero_grad() # обнуляем градиенты\n","        pred_class = model_output.argmax().item() # извлекаем прогноз модели\n","\n","        # делаем заготовку из 0 и 1, чтобы совершить backward pass по параметрам интересующего нас изображения\n","\n","        grad_target_map = torch.zeros(model_output.shape,\n","                                      dtype=torch.float)\n","        if target_class is not None:\n","            grad_target_map[0][target_class] = 1\n","        else:\n","            grad_target_map[0][pred_class] = 1\n","\n","        model_output.backward(grad_target_map)\n","\n","        result = self.image_reconstruction.data[0].permute(1,2,0) # готовим результат к визуализации\n","        return result.numpy()\n","```\n","\n","1. Во-первых, добавим возможность строить Guided backpropagation от любого интересующего нас класса. Для этого функция будет принимать аргумент `target class`. По умолчанию Guided backpropagation будем строить для спрогнозированного класса.\n","2. Во-вторых, все результаты будем возвращаться в виде numpy array.\n","\n","**Теперь соберем все воедино и закончим класс.**\n"],"metadata":{"id":"HdAF8NPEtbWt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBTFVnAV0-uQ"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torchvision import models, transforms\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","\n","\n","def identify_model(model):\n","    return model.__class__.__name__\n","\n","\n","class Guided_backprop():\n","    def __init__(self, model):\n","        self.model = model\n","        self.image_reconstruction = None # Здесь будет итоговая карта активаций\n","        self.activation_maps = []  # сюда будем записывать f1, f2, ...\n","        self.model.eval()\n","        self.register_hooks()\n","\n","    def register_hooks(self):\n","        def first_layer_hook_fn(module, grad_in, grad_out):\n","            self.image_reconstruction = grad_in[0]\n","\n","        def forward_hook_fn(module, input, output):\n","            self.activation_maps.append(output)\n","\n","        def backward_hook_fn(module, grad_in, grad_out):\n","            grad = self.activation_maps.pop() # извлекаем последнюю карту в списке (f_l, f_l-1, f_l-2...)\n","\n","            # логическая функция при forward pass, после ReLU\n","            # если выходное значение не было равно 0, то делаем его единицей\n","            # и нулём иначе if the output value is positive, we set the value to 1,\n","            # and if the output value is negative, we set it to 0.\n","            grad[grad > 0] = 1\n","\n","            #grad_out[0] будем записывать градиенты для каждой карты признаков\n","            # только если градиентны были больше нуля\n","            positive_grad_out = torch.clamp(grad_out[0], min=0.0)\n","\n","            #Логическое И над результатами (эквивалетно умножению)\n","            new_grad_in = positive_grad_out * grad\n","\n","            return (new_grad_in,)\n","\n","\n","        # AlexNet model\n","        modules = list(self.model.named_modules())\n","\n","        # двигаемся по модулям, извлекам карты при forward и backward\n","        # для ReLU\n","        for name, module in modules:\n","            if isinstance(module, nn.ReLU):\n","                module.register_forward_hook(forward_hook_fn)\n","                module.register_backward_hook(backward_hook_fn)\n","\n","        ##RESNET\n","\n","        if 'resnet' in identify_model(self.model).lower():\n","          first_layer = modules[1][1]\n","          first_layer.register_backward_hook(first_layer_hook_fn)\n","\n","        ###ALEXNET\n","\n","        if 'alexnet' in identify_model(self.model).lower():\n","          first_layer = modules[1][1][0]\n","          first_layer.register_backward_hook(first_layer_hook_fn)\n","\n","\n","    def visualize(self, input_image, target_class):\n","\n","\n","        model_output = self.model(input_image) # прогнозируем класс\n","        self.model.zero_grad() # обнуляем градиентны\n","        pred_class = model_output.argmax().item() # извлекаем метку класса\n","\n","        # делаем заготовку из 0 и 1, чтобы совершить backward pass по параметрам интересующего нас изображения\n","        grad_target_map = torch.zeros(model_output.shape,\n","                                      dtype=torch.float)\n","        if target_class is not None:\n","            grad_target_map[0][target_class] = 1\n","        else:\n","            grad_target_map[0][pred_class] = 1\n","\n","        model_output.backward(grad_target_map)\n","\n","        result = self.image_reconstruction.data[0].permute(1,2,0) # готовим результат к визуализации\n","        return result.numpy()\n","\n","def normalize(image):\n","    \"Функция для улучшения читаемости построенной карты\"\n","    norm = (image - image.mean())/image.std()\n","    norm = norm * 0.1\n","    norm = norm + 0.5\n","    norm = norm.clip(0, 1)\n","    return norm"]},{"cell_type":"code","source":["guided_bp = Guided_backprop(model)\n","result = guided_bp.visualize(tensor, None)\n","\n","result = normalize(result)\n","plt.imshow(result)\n","plt.show()"],"metadata":{"id":"HHTLKhHFZlnf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Постройте карту по классу tiger cat (282). Изменилась ли она?"],"metadata":{"id":"Ntc1nc8hu2wu"}},{"cell_type":"code","source":["guided_bp = Guided_backprop(model)\n","result1 = guided_bp.visualize(tensor, 282)\n","\n","result1 = normalize(result)\n","plt.imshow(result1)\n","plt.show()"],"metadata":{"id":"0-OLJ_bDtrus"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Постройте Guided backprop по любому случайному классу. Сильно ли меняется результат?"],"metadata":{"id":"UReR8ZoLwP0M"}},{"cell_type":"code","source":["guided_bp = Guided_backprop(model)\n","result = guided_bp.visualize(tensor, 100)\n","\n","result = normalize(result)\n","plt.imshow(result)\n","plt.show()"],"metadata":{"id":"KW2Hft8Eu9uK"},"execution_count":null,"outputs":[]}]}