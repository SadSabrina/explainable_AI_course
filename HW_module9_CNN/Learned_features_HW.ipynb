{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48v3qRs8iklJ"
   },
   "source": [
    "# **Learned features в CNN: Практика**\n",
    "\n",
    "Добро пожаловать в практическую часть по первой части модуля [\"Методы объяснения в DL\"](https://stepik.org/a/198640)!\n",
    "\n",
    "Повторим пройденные тезисы:\n",
    "\n",
    "1. Сверточные нейронные сети извлекают паттерны изображения благодаря skip-connections и сверточным слоям\n",
    "2. Извлеченные из изображения структуры для обученной сверточной сети можно увидеть,пропустив пример через слои свертки с весами последовательно\n",
    "3. Сверточные нейронные сети способны извлекать понятные человеку концепции из данных\n",
    "\n",
    "Чтобы убедится в каждом, перейдем к практике!\n",
    "\n",
    "**Quiz 1. Какой из тезисов 1-3, предложенных в начале, содержит ошибку?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1w9EdWVfhF1h"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lWxeUtEhLXp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-IjhQ2-j8SB"
   },
   "source": [
    "Будем работать с ResNet18, также известной как Residual Network — достаточно популярной архитектурой для задачи классификации. Основная особенность ResNet — использование остаточных связей (skip connections), что позволяет эффективно обучать очень глубокие сети, избегая проблемы затухания градиентов.\n",
    "\n",
    "В ResNet18, согласно названию, используется 18 слоёв. Размер входного слоя сети 224 x 224. После, грубо говоря, принятия изображения в сеть последовательно применяются слои свертки c MaxPooling, Batch Normalization и функциями активации.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYnmhJ13i74e"
   },
   "source": [
    "## Архитектура ResNet18\n",
    "\n",
    "![temp-Imageb9-Tg-EC.avif](https://www.researchgate.net/profile/Sajid-Iqbal-13/publication/336642248/figure/fig1/AS:839151377203201@1577080687133/Original-ResNet-18-Architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5miDsJwubdX"
   },
   "source": [
    "Загрузим преобученную модель из pyTorch и посмотрим на её архитектуру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbrIvRGwhrAt"
   },
   "outputs": [],
   "source": [
    "# Загрузка модели\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "#Рассмотрение архитектуры\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l4BEgnRuwK6"
   },
   "source": [
    "**Quiz 2: Какая функция активации применяется в ResNet18?** \\\n",
    "**Quiz 3: Сколько слоев свертки содержит данная архитектура ResNet18?** \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9YujXYzaBJG"
   },
   "source": [
    "Вспомним ешё несколько деталей из модуля:\n",
    "\n",
    "- Первые (от входного слоя) сверточные слои изучают абстрактные составляющие\n",
    "- Следующие слои изучают отдельные текстуры\n",
    "- Ближе к последним сверточным слоям в извлекаемой информации просматриваются паттерны,\n",
    "- В конце можно увидеть изображения\n",
    "\n",
    "также, мы зафиксировали, что эти концепции возможно увидеть в любой обученной сверточной нейроной сети, применяя слои свертки с их весами к данным последовательно.\n",
    "\n",
    "Тогда сформулируем, что нам нужно:\n",
    "\n",
    "1. Рассмотреть обученную сеть $net(img)$, содержающую $n$ слоев свертки с фиксированными весами $w_i, i=\\vec{1, n}$.\n",
    "2. Для каждого слоя внутри сети\n",
    "    - если он является сверточным, извлечь слой с его параметрами\n",
    "    - иначе пойти дальше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu3Yj_RrRvPj"
   },
   "source": [
    "Для решения задачи мы могли бы написать пройстой цикл, но архитектура ResNet18 предполагает, что свертки являются частями последовательного (*Sequential*) слоя. Учитывая это, наш алгоритм придется немного преобразовать:\n",
    "\n",
    "1. Рассмотреть обученную сеть $net(img)$, содержающую $n$ слоев свертки с фиксированными весами $w_i, i=\\vec{1, n}$.\n",
    "2. Для каждого слоя внутри сети\n",
    "    - если он является сверточным, извлечь слой с его параметрами\n",
    "    - иначе если слой является Sequential\n",
    "        - рассмотреть каждую его составляющую\n",
    "        - если составляющая является сверточным слоем, извлечь её с её параметрами\n",
    "        - иначе пойти дальше\n",
    "\n",
    "И таким способом нам надо пройтись по сети. Сделаем ниже в коде."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c9RcFQDcVHk"
   },
   "source": [
    "В действительности, для визуализации мы не будем извлекать все слои, а ограничимся меньшим их числом — 17ю. Делать мы это будем потому что 3 слоя свертки содержатся в подблоке *downsamle*.\n",
    "\n",
    "![temp-Imagermy-OBM.avif](https://i.postimg.cc/25Bg8bVX/temp-Imagermy-OBM.avif)\n",
    "\n",
    " Оператор `print` этого не отражает, но свертки в downsmapling применяются не линейно, а парралельно сверткам выше в базовом блоке (`BasicBlock`). Их параметры пробрасываются в следующий блок, поэтому не извлекая их отдельно мы ничего не теряем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1720712721855,
     "user": {
      "displayName": "Сабрина Садиех",
      "userId": "02783317471993275941"
     },
     "user_tz": -180
    },
    "id": "QsTyZPANZhQv",
    "outputId": "616a3299-ca6e-414c-9791-1378bad7aa6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Извлечено слоёв: 20\n"
     ]
    }
   ],
   "source": [
    "# Списки для извлечения сверточных слоев и их весов\n",
    "conv_weights = [] # список для весов слоя\n",
    "conv_layers = [] # список для хранения самих слоев\n",
    "\n",
    "counter = 0 # счетчик для того, чтобы убедиться, что мы извлекли все слои\n",
    "\n",
    "# сохраним все компоненты модели в список\n",
    "model_children = list(model.children())\n",
    "\n",
    "\n",
    "for i in range(len(model_children)):\n",
    "    if type(model_children[i]) == nn.Conv2d:\n",
    "        counter+=1\n",
    "        conv_weights.append(model_children[i].weight)\n",
    "        conv_layers.append(model_children[i])\n",
    "    elif type(model_children[i]) == nn.Sequential:\n",
    "      for j in range(0, len(model_children[i])):\n",
    "        for child in model_children[i][j].children():\n",
    "          if type(child) == nn.Conv2d:\n",
    "                    counter+=1\n",
    "                    conv_weights.append(child.weight)\n",
    "                    conv_layers.append(child)\n",
    "          elif type(child) == nn.Sequential and len(list(child.children())) != 0:\n",
    "            for k in range(0, len(list(child.children()))):\n",
    "              if type(list(child.children())[k]) == nn.Conv2d:\n",
    "                counter+=1\n",
    "                conv_weights.append(list(child.children())[k].weight)\n",
    "                conv_layers.append(list(child.children())[k])\n",
    "\n",
    "\n",
    "print(f'Извлечено слоёв: {counter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWS635sHfGdw"
   },
   "source": [
    "**Quiz 4:** Исправьте код ниже так, чтобы он извлек все сверточные слои, кроме тех, что содержатся в downsmaple подблоках. Сколько слоев у вас получилось после исправления? \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpREl62YhtH3"
   },
   "outputs": [],
   "source": [
    "# Списки для извлечения сверточных слоев и их весов\n",
    "conv_weights = [] # список для весов слоя\n",
    "conv_layers = [] # список для хранения самих слоев\n",
    "\n",
    "counter = 0 # счетчик для того, чтобы убедиться, что мы извлекли все слои\n",
    "\n",
    "# сохраним все компоненты модели в список\n",
    "model_children = list(model.children())\n",
    "\n",
    "for i in range(len(model_children)):\n",
    "    if type(model_children[i]) == nn.Conv2d:\n",
    "        counter+=1\n",
    "        conv_weights.append(model_children[i].weight)\n",
    "        conv_layers.append(model_children[i])\n",
    "    elif type(model_children[i]) == nn.Sequential:\n",
    "      for j in range(0, len(model_children[i])):\n",
    "        for child in model_children[i][j].children():\n",
    "          if type(child) == nn.Conv2d:\n",
    "                    counter+=1\n",
    "                    conv_weights.append(child.weight)\n",
    "                    conv_layers.append(child)\n",
    "          elif type(child) == nn.Sequential and len(list(child.children())) != 0:\n",
    "            for k in range(0, len(list(child.children()))):\n",
    "              if type(list(child.children())[k]) == nn.Conv2d:\n",
    "                counter+=1\n",
    "                conv_weights.append(list(child.children())[k].weight)\n",
    "                conv_layers.append(list(child.children())[k])\n",
    "\n",
    "\n",
    "print(f'Извлечено слоёв: {counter}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVjVvI9dp1i-"
   },
   "source": [
    "**Входное изображение.**\n",
    "\n",
    "Загрузим конкретный пример $x_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJ_FehPmLQSN"
   },
   "outputs": [],
   "source": [
    "# Загрузка изображения\n",
    "url = 'https://github.com/SadSabrina/explainable_AI_course/blob/main/HW_module9_CNN/pig.png?raw=true'\n",
    "\n",
    "image_bytes = requests.get(url).content\n",
    "image = Image.open(BytesIO(image_bytes))\n",
    "image = image.convert(\"RGB\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1720721824286,
     "user": {
      "displayName": "Сабрина Садиех",
      "userId": "02783317471993275941"
     },
     "user_tz": -180
    },
    "id": "xDuM29iUrasr",
    "outputId": "06564e5e-3afe-45dc-c96b-76672bcba652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image size: (2066, 1438)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original image size: {image.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1720721826738,
     "user": {
      "displayName": "Сабрина Садиех",
      "userId": "02783317471993275941"
     },
     "user_tz": -180
    },
    "id": "26JKM1zT2qlI",
    "outputId": "5abc6ca0-3ee8-463c-a47f-84b9178edb85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1438, 2066, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(image).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVzYVq1OA2wQ"
   },
   "source": [
    "По умолчанию png имеет 4 канала, 4й — отвлечает за прозрачность пикселя. Исправьте изображение так, чтобы работать с RGB каналами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXQxEWdjA8aI"
   },
   "outputs": [],
   "source": [
    "#Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4zSmbmBrjFQ"
   },
   "source": [
    "На вход ResNet18 может быть подано изображение любого разрешения. Проходя свертки последовательно и благодаря `AdaptiveAvgPool2d` изображение обработается в любом случае. Однако, чтобы облегчить и ускорить обработку изображения, мы изменим его размеры до 1024x1024 и нормализуем.\n",
    "\n",
    "Обратите внимание, что mean и std мы задаем сразу, не вычисляя. Для моделей, обученных на Imagenet данные значения являются обычной практикой. Они были рассчитаны на основе изображений датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1720712724262,
     "user": {
      "displayName": "Сабрина Садиех",
      "userId": "02783317471993275941"
     },
     "user_tz": -180
    },
    "id": "A8_U9Yz4hMHc",
    "outputId": "c2f79cb6-60cb-48b8-ebbe-4116f39c9532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape after resizing: torch.Size([3, 1224, 1224])\n"
     ]
    }
   ],
   "source": [
    "#Средние\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1224, 1224)),  # Изменяем размер изображения\n",
    "    transforms.ToTensor(),  # Конвертируем картинку в pyTorch тензор\n",
    "    transforms.Normalize(mean=mean, std=std)  # Нормализуем картинку\n",
    "])\n",
    "\n",
    "image = transform(image)\n",
    "print(f\"Image shape after resizing: {image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7659,
     "status": "ok",
     "timestamp": 1720712731917,
     "user": {
      "displayName": "Сабрина Садиех",
      "userId": "02783317471993275941"
     },
     "user_tz": -180
    },
    "id": "QqGWR8Tyhv1h",
    "outputId": "c91e05a9-da05-4534-95b0-b0b4784557ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:08,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Переместим модель на GPU iесли это возможно\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "image = image.to(device)\n",
    "\n",
    "# Определим списки для извлечения feature maps\n",
    "feature_maps = []  # Список для feature maps\n",
    "layer_names = []  # Список для layer names\n",
    "\n",
    "\n",
    "for number, layer in tqdm(enumerate(conv_layers)):\n",
    "    proccess = round((number+1)/17*100, 2)\n",
    "    image = layer(image)\n",
    "    feature_maps.append(image)\n",
    "    layer_names.append(str(number+1)+'_'+str(layer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMKTwnbthxbA"
   },
   "outputs": [],
   "source": [
    "# Предобработка feature maps к визуализируемому виду\n",
    "processed_feature_maps = [] # Список для хранения полученных карт активации\n",
    "for feature_map in feature_maps:\n",
    "\tfeature_map = feature_map.squeeze(0) # Удаляем размерность батча\n",
    "\tmean_feature_map = torch.sum(feature_map, 0) / feature_map.shape[0] # Вычисляем среднее по каналам\n",
    "\tprocessed_feature_maps.append(mean_feature_map.data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1ST83Wjvgp0"
   },
   "source": [
    "Наконец, отобразим получившиеся результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPzzBC2Wj4Zs"
   },
   "outputs": [],
   "source": [
    "# Отобразим карты признаков\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "for i in range(len(processed_feature_maps)):\n",
    "\tax = fig.add_subplot(5, 4, i + 1)\n",
    "\tax.imshow(processed_feature_maps[i])\n",
    "\tax.axis(\"off\")\n",
    "\tax.set_title(layer_names[i].split('(')[0], fontsize=25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEoKPXftvuL7"
   },
   "source": [
    "**Quiz 5: Почему хрюша получилась зелёной?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3bwXN24tD9I"
   },
   "source": [
    "**Quiz 6: Поэкспериментируйте с `transfroms.Resize` в `transform`. За что он отвечает в данном случае?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7og8Ox1byGZ1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMFGSba2qqGJDCADihrHZkK",
   "mount_file_id": "1S2o8JaXagSJDZ7Q6FeWIc3hBDnjKtwfX",
   "provenance": [
    {
     "file_id": "1HJT-LTo2KFO6u13-x15B8JFuY3XwMJwO",
     "timestamp": 1720710970480
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
